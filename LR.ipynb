{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "# For reproducibility, set the initial seed\n",
    "seed = 7\n",
    "np.random.seed(7)\n",
    "def load_dataset(dataset_fp, delimiter=\",\",chunksize=1000):\n",
    "    if not os.path.isfile(dataset_fp):\n",
    "        response = urlopen(\"http://cs.mcgill.ca/~ksinha4/datasets/kaggle/\" + dataset_fp)\n",
    "        CHUNK = 16 * chunksize\n",
    "        with open(dataset_fp, 'wb') as f:\n",
    "            while True:\n",
    "                chunk = response.read(CHUNK)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                f.write(chunk)\n",
    "    \n",
    "    \n",
    "    chunks = []\n",
    "    pb = progressbar.ProgressBar()\n",
    "    for chunk in pb(pd.read_csv(dataset_fp, delimiter=delimiter, chunksize=chunksize, header=None)):\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "    dataset = pd.concat(chunks)\n",
    "    return dataset.as_matrix()\n",
    "\n",
    "\n",
    "def train_validation_set_split(trainset_x, trainset_y, **kwargs):\n",
    "    trainset = np.concatenate((trainset_x, trainset_y),axis=1)\n",
    "    return train_test_split(trainset, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some preprocessing \n",
    "\n",
    "import math\n",
    "import skimage \n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.util import pad\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from scipy import ndimage\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "def get_regions_otsu_method(image):\n",
    "    bw = closing(image > 0.99, square(1))\n",
    "    \n",
    "    # label image regions\n",
    "    label_image = label(bw)\n",
    "    return [region.image for region in regionprops(label_image)]\n",
    "\n",
    "def max_region_by_area(regions):\n",
    "    return max(regions, key = lambda x : max(x.shape[0] * x.shape[0], x.shape[1] * x.shape[1]))\n",
    "\n",
    "\n",
    "def to_squre(region):\n",
    "    #convert rectangular image to square, keeping the ratio\n",
    "    (h, w) = region.shape\n",
    "    desired_size = 32\n",
    "    delta_w = desired_size - w\n",
    "    delta_h = desired_size - h\n",
    "    padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "    im = Image.fromarray(region.astype('uint8')*255)\n",
    "    new_im = ImageOps.expand(im, padding)\n",
    "    im_array = np.array(new_im)\n",
    "    transformed_im = skimage.transform.resize(im_array, (desired_size,desired_size))\n",
    "    return transformed_im\n",
    "\n",
    "def preprocess_image(image):\n",
    "    p_image = image.reshape(64,64)\n",
    "    p_image = p_image.astype('float32')\n",
    "    regions = get_regions_otsu_method(p_image)\n",
    "    max_area_region = max_region_by_area(regions)\n",
    "    return to_squre(max_area_region)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainload = load_dataset(\"train_x.csv\")\n",
    "ytrainload = load_dataset(\"train_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrainload / 255.0\n",
    "ytrain = ytrainload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = progressbar.ProgressBar()\n",
    "\n",
    "# preprocess x \n",
    "xtrain_preprocessed = []\n",
    "for x in pb(xtrain):\n",
    "    result = preprocess_image(x)\n",
    "    result = result.reshape(1024)\n",
    "    xtrain_preprocessed.append(result)\n",
    "xtrain = np.asarray(xtrain_preprocessed)\n",
    "\n",
    "num_classes = ytrain.shape[1]\n",
    "\n",
    "\n",
    "xtrainset = xtrain[:-10000]\n",
    "ytrainset = ytrain[:-10000]\n",
    "xvalidset = xtrain[-10000:]\n",
    "yvalidset = ytrain[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression() \n",
    "clf = clf.fit(xtrainset,ytrainset.ravel())\n",
    "y_pred_log = clf.predict(xvalidset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \",metrics.accuracy_score(yvalidset, y_pred_log))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
